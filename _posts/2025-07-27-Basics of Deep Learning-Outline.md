---
title: "[Basics of Deep Learning] Outline"
date: 2025-07-27 08:00:00 +09:00
categories: [ML] 
tags: []     
math: true
layout: post
author: birm
---

This post outlines the course _Basics of Deep Learning (SNU, Spring 2025)_. Specific content for each lecture will be added incrementally.
# Course Content
The course material is organized sequentially following the lecture flow:

1. What is Machine Learning (ML), the types of ML problems, and categories of ML models (Discriminative vs. Generative)
2. Learning via loss functions in ML, principles of backpropagation, and implementing it using computational graphs  
3. Basic neural networks: Linear NNs, CNNs, and various techniques (Pooling, BatchNorm, Weight Initialization, etc.)  
4. Sequence-to-sequence neural networks: RNN, LSTM, Attention, Transformer  
5. Hands-on implementation of Attention and Transformer in PyTorch (forward and backward passes + inference)  
6. Generative Models (1): Autoencoders, Variational Autoencoders (VAE), Generative Adversarial Networks (GAN)  
7. Generative Models (2): Score-based Generative Models, Denoising Diffusion Probabilistic Models (DDPM)  
8. Adversarial attacks and defense methods  
9. Information theory and disentanglement + advanced VAE variants based on information theory ($\beta$-VAE, FactorVAE, CascadeVAE)  
10. Metric learning â€“ classification problems with extremely large label sets  
11. Reinforcement Learning (RL): Basics (Bellman equations, etc.) and Deep RL (Policy Gradient, DQN, etc.)  
12. Data augmentation and mixup strategies (Manifold Mixup, CutMix, Co-Mixup)  
13. Network pruning and quantization techniques  

